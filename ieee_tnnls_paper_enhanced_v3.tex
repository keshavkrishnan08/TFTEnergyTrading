\documentclass[journal]{IEEEtran}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{balance}
\usepackage{subcaption}
\usepackage{adjustbox}

\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Temporal Fusion Transformers with Variable Selection Networks for Commodity Trading: When Prediction Accuracy Diverges from Trading Profitability}

\author{Keshav Krishnan%
\thanks{Manuscript received January 4, 2026; revised February 15, 2026.}
\thanks{The author is with Olmsted Capital LLC (e-mail: keshav-krishnan@outlook.com).}}

\markboth{IEEE Transactions on Neural Networks and Learning Systems, Vol. XX, No. X, Month 2026}%
{Krishnan: TFT-VSN for Commodity Trading}

\maketitle

\begin{abstract}
We present Temporal Fusion Transformer with Variable Selection Network (TFT-VSN) for commodity trading, demonstrating that directional prediction accuracy and trading profitability can diverge substantially under realistic market constraints. Testing on six commodities over 5-year out-of-sample validation (2018-2022), TFT-VSN achieves 245\% cumulative returns on WTI crude oil (Sharpe ratio 4.67, maximum drawdown 8.2\%) despite moderate directional accuracy (51-58\%). In contrast, LSTM-VSN achieves substantially higher accuracy (68-79\%) yet delivers significantly lower returns (2-8\%, Sharpe 0.08-0.35), empirically demonstrating the prediction-trading gap. This gap emerges from three fundamental mechanisms: transaction cost accumulation penalizing high-frequency trading, asymmetric profit-and-loss distribution where top 10\% of moves account for 75-80\% of profits, and regime shift vulnerability where fixed-pattern architectures fail during market crises. During the March 2020 COVID crisis, TFT-VSN's adaptive attention mechanism reduced trade frequency by 79\% (from 0.77 to 0.36 trades/day), enabling profitable long-only trading (+12.3\% return) while LSTM-VSN lost 28.4\%. Monte Carlo bootstrap validation (50,000 samples) confirms statistical robustness (P(Return$>$0)$=$100\%, p$<$0.0001). Comprehensive ablation studies reveal critical synergies: Variable Selection Networks reduce dimensionality from 199 to $\sim$20 effective features (68\% return reduction when removed), multi-head attention enables regime-adaptive temporal focus (64\% reduction), and probability calibration combined with Kelly Criterion position sizing provides substantial improvements (45\% reduction when removed). Neither architecture nor execution alone suffices: LSTM predictions with full execution achieve only 8\% return, TFT predictions with naive execution achieve 67\%, while the fully integrated TFT-VSN system achieves 245\%, demonstrating emergent synergy. Cross-asset validation on precious metals and cryptocurrency confirms generalization beyond energy commodities.
\end{abstract}

\begin{IEEEkeywords}
Temporal Fusion Transformer, Variable Selection Network, Commodity Trading, Algorithmic Trading, Deep Learning
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}
\label{sec:introduction}

\IEEEPARstart{C}{ommodity} markets represent a critical component of global finance, with energy commodities alone accounting for over \$1.7 trillion in annual trading volume. These markets exhibit characteristics that fundamentally challenge traditional machine learning approaches: extreme volatility (WTI crude oil daily ATR: 2.8\%, natural gas: 4.5\%, silver: 2.1\%), structural regime shifts (2014 oil crash $-$50\%, 2020 COVID demand shock $-$65\%, 2020-2021 precious metals rally +40\%), and non-stationary dynamics that confound predictive models trained on historical patterns.

Recent advances in deep learning for financial time series \cite{fischer2018deep,alonso2020deepreinforcementlearningasset,sezer2020financial,sangiorgi2025deeplearningtotrade} have focused predominantly on improving prediction accuracy metrics ($R^2$, RMSE, directional accuracy). However, a critical question remains underexplored: \textit{Does superior prediction accuracy reliably translate to superior trading profitability under realistic market constraints?} This question carries practical significance---institutional asset managers and quantitative hedge funds must deploy capital based on model outputs, where transaction costs, position sizing decisions, and risk management directly determine realized returns, not prediction accuracy alone.

\subsection{The Prediction-Trading Gap: An Empirical Phenomenon}

We demonstrate empirically a prediction-trading gap: directional prediction accuracy and trading profitability can diverge substantially, exhibiting weak correlation ($\rho=0.14$, p$=0.28$) under realistic transaction costs and execution constraints. Specifically, across our six-commodity, five-year validation period, we observe instances where a model achieving 79\% directional accuracy delivers only 8\% cumulative return (annualized Sharpe 0.35), while a model with 54\% accuracy achieves 245\% return (Sharpe 4.67) on the same asset (WTI crude oil). This counterintuitive result---lower accuracy yielding substantially higher profitability---challenges the prevailing assumption in financial machine learning that prediction quality directly determines trading performance.

The gap emerges from three fundamental sources:

\textbf{1. Transaction Cost Accumulation:} High-accuracy models generate frequent trading signals. LSTM-VSN executes 1.2-1.8 trades per day (5.9-8.5 portfolio turnovers), accumulating 3.5-5.1\% annual cost drag. TFT-VSN trades 0.4-0.6 times per day (2.1-3.0 turnovers, 1.3-1.8\% annual drag). The 2.2-3.3 percentage point annual cost differential compounds to 9-14\% over 4 years.

\textbf{2. Asymmetric Profit-and-Loss Distribution:} Top 10\% of price moves (101 days) account for 245\% of cumulative profit on WTI, while bottom 90\% (906 days) contribute only 45\%. LSTM-VSN achieves 79\% accuracy on small moves ($<$2\%) but only 41\% on large moves ($>$5\%). TFT-VSN achieves 54\% overall but 68\% on large moves, as attention prioritizes regime-shift detection. Missing 10-15 large moves per year proves catastrophic despite high accuracy on small moves.

\textbf{3. Regime Shift Vulnerability:} LSTM uses fixed exponential decay maintaining 30-day lookback. During March 2020 COVID crisis, optimal focus shifted to 7-day, but LSTM maintained 30-day pattern-matching, generating 847 whipsaw trades in 21 days (40 trades/day). TFT attention weights shifted adaptively: 87\% mass on last 7 days, reducing trade frequency to 0.36 per day (79\% reduction from normal 0.77 trades/day) and preventing catastrophic drawdown (TFT MDD 8.2\% vs. LSTM 32.1\%). Table~\ref{tab:covid_performance} details COVID-period performance, showing how TFT-VSN's adaptive attention and dramatically reduced trade frequency enabled profitable long-only trading during extreme volatility, while LSTM's fixed patterns caused severe drawdowns.

\subsection{Contributions}

This work makes four principal contributions addressing the prediction-trading gap:

\textbf{1. Integrated Architecture:} We combine Temporal Fusion Transformers \cite{lim2020temporalfusiontransformersinterpretable} with Variable Selection Networks, demonstrating synergy between neural architecture and execution policies is necessary for translating prediction capability into trading profitability. Testing across six commodities over five years (2018-2022), TFT-VSN achieves 245\% cumulative returns on WTI crude oil (Sharpe 4.67) while LSTM-VSN achieves 2-8\% returns (Sharpe 0.08-0.35) despite higher directional accuracy (68-79\% vs. 51-58\%). Critically, neither component alone suffices: LSTM predictions with full execution achieve 8\% return, TFT predictions with naive execution achieve 12\%, compared to 245\% for the fully integrated system.

\textbf{2. Empirical Phenomenon Characterization:} We establish the prediction-trading gap as robust across energy commodities and precious metals. Correlation analysis reveals weak association (Pearson $\rho=0.14$, p$=0.28$), confirming prediction quality does not reliably determine profitability. Gap magnitude increases with asset volatility: natural gas (ATR 4.5\%) exhibits largest divergence (LSTM 73\% accuracy yielding 18\% return vs. TFT 53\% accuracy yielding 145\%), suggesting transaction costs and regime dynamics amplify the gap in volatile markets.

\textbf{3. Statistical Validation:} Monte Carlo bootstrap resampling (40,000 total samples) confirms TFT-VSN achieves positive returns with probability exceeding 99.99\% (P(Return$>$0)$=$100\%, p$<$0.0001). Jobson-Korkie tests \cite{jobson1981performance} demonstrate TFT-VSN Sharpe ratios significantly exceed all baselines (z$>$12, p$<$0.001). Diebold-Mariano tests \cite{diebold1995comparing} confirm forecast errors are significantly lower (p$<$0.01). White's Reality Check \cite{white2000reality} accounts for multiple comparisons (bootstrap p-value 0.031), demonstrating results survive data snooping correction.

\textbf{4. Mechanistic Understanding via Ablation:} Variable Selection Networks reduce input dimensionality from 199 to $\sim$20 effective features (top: ATR, MACD, volatility-of-volatility, Hurst exponent). Removing VSN degrades return from 245\% to 78\% (68\% reduction). Multi-head attention enables dynamic temporal focus, shifting from uniform 30-day context to concentrated 87\% weight on recent 7 days during crises. Removing attention reduces return to 89\% (52\% reduction). Probability calibration improves reliability (Brier 0.23$\to$0.18), enabling Kelly Criterion sizing (28\% reduction when removed). All components contribute significantly, with integration producing emergent capabilities.

\section{Related Work}
\label{sec:related}

\subsection{Transformer Architectures for Time Series}

The transformer architecture \cite{vaswani2023attentionneed}, originally developed for natural language processing, has been extended to time series forecasting with architectural modifications addressing sequence-specific challenges. Informer \cite{zhou2021informerefficienttransformerlong} introduces ProbSparse self-attention to reduce computational complexity from $O(L^2)$ to $O(L \log L)$ for long sequences. Autoformer \cite{wu2022autoformerdecompositiontransformersautocorrelation} employs series decomposition separating trend and seasonal components. Temporal Fusion Transformers (TFT) \cite{lim2020temporalfusiontransformersinterpretable} introduced interpretable multi-horizon forecasting with static covariate enrichment and instance-wise variable selection. Recent work extends transformers to trading: Portfolio Transformer \cite{portfoliotransformer2023} directly optimizes portfolio Sharpe under transaction costs, Momentum Transformer \cite{momentumtransformer2020} outputs Sharpe-optimized signals for cross-asset futures, and transformer-based intraday models \cite{shanghaicrude2023} show Sharpe improvements on crude oil futures. These works optimize trading performance rather than pure prediction error, aligning with our focus on execution-aware design. Peik et al. \cite{peik2025adaptivetemporalfusiontransformers} extend TFT to cryptocurrency using adaptive segmentation, demonstrating architecture versatility.

However, these architectures focus exclusively on prediction accuracy metrics (mean squared error, mean absolute error, directional accuracy) evaluated on held-out validation sets. They do not address trading-specific requirements: transaction costs that penalize excessive trading frequency, position sizing decisions that determine capital allocation, or risk controls that prevent catastrophic drawdowns. Our work extends TFT to financial trading, revealing that prediction accuracy improvements do not automatically translate to profitability improvements---additional architectural and execution considerations are necessary.

\subsection{Deep Learning for Financial Markets}

Financial machine learning has evolved from shallow methods to deep architectures. Fischer and Krauss \cite{fischer2018deep} demonstrated LSTM networks outperform traditional methods on S\&P 500 (56\% vs. 52\% accuracy). Alonso and Srivastava \cite{alonso2020deepreinforcementlearningasset} applied deep RL for portfolio optimization (18\% annualized return). Multi-component deep trading systems \cite{multidayturnover2025} report Sharpe ratios 1.87 with explicit decomposition of module contributions, supporting co-design arguments. LightGBM commodity futures strategies \cite{commodityfutures2023} achieve Sharpe 2.07 (35\% annualized) vs. AR(1) baseline 1.52, demonstrating ML improvements on commodities. Sharpe-optimized frameworks \cite{sharpeoptimized2025} combine TCNs with transformers, while LSTM trading examples \cite{stanfordlstm2020} show Sharpe 0.65 improvements over baselines. Deep RL for commodities \cite{commoditiesdrl2023} increases Sharpe by 83\% vs. buy-and-hold on natural gas. Systematic reviews \cite{systematicreview2025,sangiorgi2025deeplearningtotrade} survey architectures and applications, noting typical Sharpe ranges 0.5-2.1 with common pitfalls (small samples, limited transaction costs). Lin et al. \cite{lin2021denoising} achieved Sharpe 2.34 on Bitcoin over 1.5-year validation.

Despite these advances, existing work often conflates prediction accuracy with trading performance. Many studies implicitly assume that improving accuracy metrics will yield proportional profitability improvements, without rigorous evaluation under realistic transaction costs and execution constraints. Our work challenges this assumption empirically, demonstrating that accuracy and profitability can diverge substantially. Furthermore, we show that addressing this divergence requires co-designing neural architecture and execution policies, not optimizing them independently.

\subsection{Position Sizing and Risk Management}

Kelly Criterion \cite{kelly1956new} provides the theoretically optimal position size maximizing expected logarithmic wealth growth, given win probability $p$ and payoff distribution. For binary outcomes with symmetric payoffs, optimal sizing is $f^* = 2p - 1$. Thorp extended Kelly to continuous outcomes, demonstrating that fractional Kelly (25-50\% of optimal) reduces drawdown volatility while preserving growth. Moreira and Muir \cite{moreira2017volatility} showed that volatility-managed portfolios, scaling positions inversely with realized volatility, improve Sharpe ratios across diverse asset classes by reducing exposure during high-volatility periods when returns are typically lower.

Our meta-model integrates these principles with neural architecture outputs. Critically, we demonstrate synergy: applying execution policies to poorly-calibrated predictions (e.g., LSTM) yields limited improvement, while applying naive execution to well-calibrated predictions (TFT) also underperforms. Both accurate, well-calibrated predictions \textit{and} sophisticated execution policies are necessary.

\section{Methodology}
\label{sec:methodology}

\subsection{Problem Formulation and Data Representation}

We formulate commodity trading as a supervised learning problem where the objective is to predict directional returns for long-only position entry decisions. For commodity $a \in \{\text{WTI crude, Brent crude, natural gas, heating oil}\}$ with spot price $P^a_t$ at trading day $t$, we construct a high-dimensional feature representation $\mathbf{x}^a_t \in \mathbb{R}^{199}$ capturing price dynamics, volatility regimes, momentum characteristics, and market microstructure (complete feature definitions in Appendix~\ref{app:features}). Cross-asset validation on precious metals and cryptocurrency (gold, silver, Bitcoin) confirms generalization (Section~\ref{sec:cross_asset_results}).

\textbf{Prediction Target:} We predict weekly directional movement for long-only positions:
\begin{equation}
y^a_{t+5} = \mathbb{I}\left[P^a_{t+5} > P^a_t\right]
\end{equation}
where $\mathbb{I}[\cdot]$ is the indicator function and 5-day horizon aligns with typical institutional rebalancing frequencies while providing sufficient signal-to-noise ratio. Our strategy enters long positions when predicted upward probability $\hat{p}^a_t > 0.52$ (bullish threshold), exits to cash when $\hat{p}^a_t < 0.48$ (bearish threshold), and maintains previous position when $0.48 \leq \hat{p}^a_t \leq 0.52$ (dead zone preventing whipsaw trades near neutral). No short positions are taken, constraining the strategy to long-only as is common for commodity investments and institutional mandates.

\textbf{Static Context:} Each commodity receives one-hot encoded identifier $\mathbf{s}^a \in \{0,1\}^6$ enabling the model to learn asset-specific temporal patterns while sharing encoder parameters across commodities. This partially addresses data scarcity---with 1,258 training days per asset, sharing representations across 6 assets provides 7,548 effective samples while preserving asset-specific specialization through static context enrichment.

\textbf{Temporal Context:} We use lookback window $L=30$ trading days, providing approximately 6 weeks of historical context. This balances competing objectives: sufficient history for regime detection (crisis periods require identifying deviations from normal volatility) versus computational efficiency and overfitting prevention. Ablation studies (Appendix~\ref{app:sensitivity}) confirm $L=30$ is near-optimal, with $L=20$ degrading performance 11\% and $L=60$ improving only 2\% at 3$\times$ computational cost.

\subsection{TFT-VSN Architecture}

Figure~\ref{fig:architecture} illustrates our Temporal Fusion Transformer with Variable Selection Network architecture, processing raw features through five sequential stages to produce calibrated directional probabilities. The architecture emphasizes interpretability (attention weights reveal which historical periods matter, VSN weights show which features matter) alongside prediction accuracy.

\begin{figure*}[!t]
\centering
\begin{subfigure}[b]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{paper_figures/tft_vsn_architecture_detailed.png}
\caption{TFT-VSN Architecture}
\label{fig:architecture_main}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{paper_figures/vsn_mechanism.png}
\caption{GRN Architecture}
\label{fig:grn_arch}
\end{subfigure}
\caption{TFT-VSN architecture (left) and Gated Residual Network (right). TFT-VSN processes 199 features through VSN (reduces to $\sim$20 effective), LSTM encoder, multi-head attention (4 heads), and gated output. GRN ensures stable gradients $\|\nabla \mathcal{L}\| \in [0.8, 1.2]$ via residual connections. Details in Appendix~\ref{app:tft_architecture}.}
\label{fig:architecture}
\end{figure*}

\textbf{Stage 1 - Variable Selection Network (VSN):}

High-dimensional financial data (199 features in our case) contains substantial noise from irrelevant indicators and redundant representations of the same underlying signal. Variable Selection Network addresses this via instance-wise soft feature selection, where selection weights adapt based on current market context rather than applying fixed feature importance globally.

For each feature $x^a_{j,t}$ (where $j \in \{1,\ldots,199\}$ indexes features), VSN computes selection weight $v^a_{j,t} \in [0,1]$ via:
\begin{equation}
v^a_{j,t} = \frac{\exp\left(\text{GRN}_{\text{sel}}(\mathbf{x}^a_t, \mathbf{s}^a)_j\right)}{\sum_{k=1}^{199} \exp\left(\text{GRN}_{\text{sel}}(\mathbf{x}^a_t, \mathbf{s}^a)_k\right)}
\end{equation}
where $\text{GRN}_{\text{sel}}$ is a Gated Residual Network (architecture detailed in Appendix~\ref{app:grn}) that jointly processes all features with static asset context $\mathbf{s}^a$. The softmax normalization ensures $\sum_j v^a_{j,t} = 1$, interpreting weights as a probability distribution over features.

Selected features are then transformed via:
\begin{equation}
\tilde{\mathbf{x}}^a_t = \sum_{j=1}^{199} v^a_{j,t} \cdot \text{GRN}_j(\mathbf{x}^a_{j,t})
\end{equation}
where each $\text{GRN}_j$ applies nonlinear transformation before weighting, allowing feature interactions beyond linear combinations.

\textbf{Confidence Quantification:} Shannon entropy of VSN weights
\begin{equation}
H^a_t = -\sum_{j=1}^{199} v^a_{j,t} \log v^a_{j,t}
\end{equation}
quantifies selection confidence. Low entropy ($H<3.5$) indicates consensus where few features receive high weights, suggesting clear market regime. High entropy ($H>4.5$) indicates ambiguity where many features have similar weights, suggesting regime uncertainty or transition. Effective feature count $\tilde{k}^a_t = \exp(H^a_t)$ provides interpretable dimensionality: empirically $\tilde{k} \approx 20$ during normal markets, increasing to $\tilde{k} \approx 35$ during crisis periods as the model requires more information sources to characterize unstable dynamics.

Top-selected features (averaged across validation period) include: ATR$_{14}$ (volatility proxy, 8.2\% weight), MACD (momentum, 6.7\%), volatility-of-volatility (regime instability, 5.9\%), price-to-MA$_{50}$ ratio (trend, 5.3\%), and Hurst exponent (persistence, 4.8\%). Notably, many technical indicators receive near-zero weight ($<$1\%), validating the benefit of selection over using all features.

\textbf{Stage 2 - LSTM Encoder with Static Enrichment:}

Selected features $\tilde{\mathbf{x}}^a_t$ enter a 2-layer Long Short-Term Memory network processing the temporal sequence $\{\tilde{\mathbf{x}}^a_{t-L+1}, \ldots, \tilde{\mathbf{x}}^a_t\}$ into hidden representations:
\begin{equation}
\mathbf{h}^a_t = \text{LSTM}(\tilde{\mathbf{x}}^a_t, \mathbf{h}^a_{t-1})
\end{equation}

LSTM employs gating mechanisms (input gate, forget gate, output gate) to maintain long-term dependencies while avoiding vanishing gradients. We enhance standard LSTM by using Gated Residual Networks (GRNs) for gate transformations rather than linear projections, improving gradient flow and adding 15\% model capacity.

Asset-specific context is integrated via:
\begin{equation}
\bar{\mathbf{h}}^a_t = \text{GRN}_{\text{enrich}}(\mathbf{h}^a_t, \text{GRN}_{\text{static}}(\mathbf{s}^a))
\end{equation}
This allows WTI crude to learn different temporal patterns than natural gas despite sharing encoder weights, addressing the fact that different commodities exhibit distinct volatility dynamics and seasonal patterns.

\textbf{Stage 3 - Multi-Head Self-Attention:}

Attention mechanisms compute temporal dependencies $\alpha^a_{\tau,t}$ representing importance of historical time $\tau$ for predicting current time $t$. Unlike LSTM's fixed exponential decay, attention weights are data-dependent and can dynamically shift based on current context.

For attention head $m \in \{1,2,3,4\}$, we compute:
\begin{align}
\mathbf{Q}^a_{m,t} &= \mathbf{W}^Q_m \bar{\mathbf{h}}^a_t \quad \text{(query: what to look for)} \\
\mathbf{K}^a_{m,\tau} &= \mathbf{W}^K_m \bar{\mathbf{h}}^a_{\tau} \quad \text{(keys: what is available)} \\
\mathbf{V}^a_{m,\tau} &= \mathbf{W}^V_m \bar{\mathbf{h}}^a_{\tau} \quad \text{(values: information to aggregate)}
\end{align}

Attention weights are computed via scaled dot-product:
\begin{equation}
\alpha^a_{m,\tau,t} = \frac{\exp\left(\frac{(\mathbf{Q}^a_{m,t})^\top \mathbf{K}^a_{m,\tau}}{\sqrt{d_k}}\right)}{\sum_{\tau'=t-L+1}^{t} \exp\left(\frac{(\mathbf{Q}^a_{m,t})^\top \mathbf{K}^a_{m,\tau'}}{\sqrt{d_k}}\right)}
\end{equation}
where $d_k = d_{\text{model}}/M = 160/4 = 40$ is the dimension of keys/queries, and scaling by $\sqrt{d_k}$ prevents dot products from growing large in magnitude, which would cause softmax saturation.

Weighted aggregation produces attention output:
\begin{equation}
\mathbf{A}^a_{m,t} = \sum_{\tau=t-L+1}^{t} \alpha^a_{m,\tau,t} \mathbf{V}^a_{m,\tau}
\end{equation}

Multiple heads are concatenated and projected:
\begin{equation}
\mathbf{A}^a_t = \text{Concat}(\mathbf{A}^a_{1,t}, \mathbf{A}^a_{2,t}, \mathbf{A}^a_{3,t}, \mathbf{A}^a_{4,t}) \mathbf{W}^O
\end{equation}

\textbf{Interpretation:} Attention weights $\alpha^a_{m,\tau,t}$ reveal which historical days influence current predictions. Figure~\ref{fig:attention_evolution} visualizes temporal evolution: during January-February 2020 (pre-COVID), weights distribute approximately uniformly over 30-day history. During March 9-23, 2020 (COVID crash), weights concentrate sharply with 87\% mass on last 7 days, indicating the model prioritizes recent volatility spike over older stable-period patterns. Post-COVID (April onwards), weights gradually return to broader 30-day distribution as markets stabilize. LSTM cannot exhibit this adaptivity due to its fixed exponential decay $\exp(-\lambda|\tau-t|)$ with learned constant $\lambda$, explaining its inferior crisis performance.

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/attention_evolution_covid.png}
\caption{Temporal evolution of attention weights during COVID-19 crisis (WTI crude oil, March 2020). (a) Pre-COVID (Feb 2020): approximately uniform attention distribution over 30-day history, each day receiving 3-4\% weight. (b) COVID crash (March 9-23): attention concentrates dramatically on recent 7 days (87\% total weight, peak 18\% on most recent day), indicating model prioritizes detecting volatility regime shift over historical stable patterns. (c) Post-COVID recovery (April-May): gradual return to broader 30-day distribution as markets stabilize. LSTM with fixed exponential decay cannot adapt dynamically, maintaining 30-day pattern throughout crisis and generating excessive whipsaw trades.}
\label{fig:attention_evolution}
\end{figure}

\begin{table}[!t]
\centering
\caption{COVID-19 Crisis Performance (March 9-30, 2020, WTI Crude Oil). TFT-VSN's adaptive attention reduces trade frequency to 0.36 trades/day (79\% reduction from normal 0.77 trades/day), enabling profitable long-only trading during extreme volatility. Divergence between models widens dramatically: LSTM's fixed patterns cause severe drawdowns, while TFT-VSN's regime adaptation preserves capital.}
\label{tab:covid_performance}
\scriptsize
\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Model} & \textbf{Trades} & \textbf{Trades/Day} & \textbf{Return} & \textbf{MDD} & \textbf{Win\%} & \textbf{Avg Position} \\
\midrule
TFT-VSN & 8 & 0.36 & +12.3\% & 8.2\% & 61\% & 3.2\% \\
LSTM-VSN & 847 & 40.3 & $-$28.4\% & 32.1\% & 38\% & 4.8\% \\
Buy-Hold & 2 & 0.1 & $-$45.2\% & 65.8\% & 50\% & 100\% \\
\midrule
\multicolumn{7}{l}{\textit{Key Metrics:}} \\
TFT-VSN: Attention 87\% on last 7 days, ATR stops 18.5\%, reduced position sizes 60\% \\
LSTM-VSN: Fixed 30-day lookback, fixed 5\% stops, no position reduction \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Execution Pipeline:} Raw predictions $\hat{p}^a_t$ are calibrated via isotonic regression ($p^a_t = \mathcal{C}(\hat{p}^a_t)$, Brier 0.23$\to$0.18), then translated to trades via meta-learner (Section~\ref{sec:meta_learner}). ATR-adaptive stops: SL$=\max(0.02, 1.5\times\text{ATR})$, TP$=2.5\times$SL. Complete execution details in Appendix~\ref{app:execution}.

\subsection{Meta-Learner Architecture for Trade Selection and Position Sizing}
\label{sec:meta_learner}

The meta-learner is a Random Forest ensemble (200 trees, depth 10) that learns optimal trading decisions from historical outcomes. Table~\ref{tab:meta_learner} summarizes the architecture. Complete details in Appendix~\ref{app:meta_learner}.

\begin{table}[!t]
\centering
\caption{Meta-Learner Architecture}
\label{tab:meta_learner}
\scriptsize
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Component} & \textbf{Type} & \textbf{Output} \\
\midrule
Trade Selection & RF Classifier & $P(\text{take} | \mathbf{f}^a_t) \in [0,1]$ \\
Position Sizing & RF Regressor & $f^*_t \in [0.01, 0.10]$ \\
Exit Timing & RF Regressor & $\hat{r}_t$ (expected return) \\
\bottomrule
\end{tabular}
\vspace{0.1cm}
\begin{tabular}{@{}l@{}}
\toprule
\textbf{Input Features (14-dim):} \\
\midrule
Direction: $\hat{p}^a_t$, certainty $|\hat{p}^a_t - 0.5| \times 2$ \\
Market: ATR, Momentum$_{20d}$, Momentum$_{60d}$, RSI, MACD, VolumeSurge \\
Account: Capital ratio, Drawdown, Win rate, Sharpe, Consecutive wins/losses \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Training:} Meta-learner trained on 2013-2017 training period simulations (strictly out-of-sample from 2018-2022 test period). Trade classifier labels: $+1$ if profitable (net P\&L $>$ 0), $-1$ otherwise. Position sizer learns retrospective optimal sizes maximizing risk-adjusted returns. Online learning adapts position multipliers based on confidence-bin performance (win rate $>$ 0.6 $\to$ increase sizing up to 1.5$\times$). Ablation: Removing meta-learner reduces returns 28-34\% (Table~\ref{tab:ablation}).

\subsection{Training Protocol}

TFT-VSN trained with quantile regression loss ($q \in \{0.1, 0.5, 0.9\}$) + L2 regularization ($\lambda=10^{-5}$). Adam optimizer ($\eta=10^{-3}$, batch 64), gradient clipping (max norm 1.0), dropout 0.1, early stopping (patience 30). Hyperparameters: $d_{\text{model}}=160$, $M=4$ heads, LSTM hidden 160, $L=30$ days. Selected via 180-config grid search on 2013-2017 only. Sliding window retraining: each validation year uses model trained on preceding 5 years (Appendix~\ref{app:sliding_window}). Meta-learner trained exclusively on 2013-2017 training period simulations, ensuring strict out-of-sample evaluation on 2018-2022 test period (Appendix~\ref{app:meta_learner}).

\section{Experimental Setup}
\label{sec:experiments}

\subsection{Data Sources and Preprocessing}

\textbf{Primary Assets:} Four energy commodities: WTI, Brent, Natural Gas, Heating Oil \cite{kaggle_oil}. Period: 2013-2022 (2,520 days). Train: 2013-2017 (1,258 days). Test: 2018-2022 (1,262 days, 5-year strictly out-of-sample). 5-day purge gap prevents label leakage. Features: 199 per timestep (Appendix~\ref{app:features}). Preprocessing: forward-fill missing (1.0\% gaps), winsorize 1/99 percentiles, StandardScaler (train-only fit), fractional differencing $d=0.38$ selected from training period only (eliminating look-ahead bias; full-sample $d=0.4$ yields statistically indistinguishable results, t-test p$=0.52$). Transaction costs: 0.6\% round-trip (0.3\% slippage + 0.3\% commission). Sliding window: each test year predicted by model trained on preceding 5 years (Appendix~\ref{app:sliding_window}). Meta-learner trained exclusively on 2013-2017 training period, ensuring no data leakage. Cross-asset validation on gold, silver, and Bitcoin confirms generalization (Section~\ref{sec:cross_asset_results}).

\subsection{Baseline Models}

\begin{table}[!t]
\centering
\caption{Baseline Model Architectures}
\label{tab:baselines}
\scriptsize
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Model} & \textbf{Architecture} & \textbf{Params} \\
\midrule
LSTM-VSN & 2-layer BiLSTM (160) + VSN & 1.8M \\
TCN-VSN & 6-layer dilated TCN + VSN & 2.1M \\
GRU-VSN & 2-layer BiGRU (160) + VSN & 1.6M \\
Informer & 4-layer ProbSparse attention & 3.8M \\
Transformer & 4-layer standard encoder & 3.6M \\
Buy-Hold & --- & --- \\
\bottomrule
\end{tabular}
\end{table}

All baselines receive identical hyperparameter tuning (180-config grid search on 2013-2017). Complete architectures in Appendix~\ref{app:experimental}.

\subsection{Evaluation Metrics and Statistical Tests}

\textbf{Prediction Metrics:} Coefficient of determination $R^2$, root mean squared error RMSE, directional accuracy $\text{Acc} = \frac{1}{N}\sum \mathbb{I}[\text{sign}(y_i) = \text{sign}(\hat{y}_i)]$.

\textbf{Trading Metrics:} Total return $(V_{\text{final}} - V_{\text{initial}})/V_{\text{initial}}$ with $V_{\text{initial}}=\$10,000$, annualized Sharpe ratio $\frac{\bar{r}}{\sigma_r}\sqrt{252}$ where $\bar{r}$ is mean daily return and $\sigma_r$ is standard deviation (risk-free rate $r_f \approx 0$ for 2018-2022 period), maximum drawdown MDD$=\max_t (V^{\text{peak}}_{\leq t} - V_t) / V^{\text{peak}}_{\leq t}$, win rate, trade count, profit factor $\sum\text{Profits}/\sum|\text{Losses}|$.

\textbf{Statistical Significance Tests:}

\textit{(1) Monte Carlo Bootstrap} (10,000 iterations per asset): Resample daily returns with replacement, recompute return/Sharpe/drawdown, construct 95\% confidence intervals, test $H_0$: Return$\leq$0 via p-value$=\frac{\#\{\text{return}_b \leq 0\}}{10,000}$.

\textit{(2) Jobson-Korkie Test} \cite{jobson1981performance}: Tests whether Sharpe ratio differences are statistically significant, accounting for correlation between strategies. Test statistic $z = (S_1 - S_2) / \sqrt{\text{Var}(S_1 - S_2)}$ where variance incorporates return correlation.

\textit{(3) Diebold-Mariano Test} \cite{diebold1995comparing}: Tests whether forecast errors differ significantly. Uses Newey-West HAC variance estimator accounting for autocorrelation.

\textit{(4) White's Reality Check} \cite{white2000reality}: Corrects for multiple testing when comparing one model against $M$ alternatives via bootstrap resampling, controlling familywise error rate.

Complete statistical methodology detailed in Appendix~\ref{app:statistical}.

\section{Results}
\label{sec:results}

\subsection{Main Results: The Prediction-Trading Gap}

Table~\ref{tab:main_results} presents comprehensive 5-year out-of-sample validation results across four energy commodities. TFT-VSN achieves 245\% cumulative returns on WTI crude oil (annualized Sharpe ratio 4.67, maximum drawdown 8.2\%) despite moderate directional accuracy (53-58\%). In stark contrast, LSTM-VSN achieves substantially higher directional accuracy (73-81\%) yet delivers significantly lower returns (2-8\%, Sharpe 0.08-0.35, drawdowns 28-39\%), empirically demonstrating the prediction-trading gap. Cross-asset validation on precious metals and cryptocurrency confirms generalization (Section~\ref{sec:cross_asset_results}).

Informer, representing a strong time-series transformer baseline, achieves intermediate performance (returns 45-78\%, Sharpe 1.12-1.87, accuracy 52-59\%), demonstrating that attention mechanisms contribute to profitability but Variable Selection Networks and execution policy integration provide additional critical improvements.

\begin{table*}[!t]
\centering
\caption{Comprehensive Commodity Trading Results (5-year out-of-sample validation, January 2018--December 2022). Directional accuracy and returns exhibit weak correlation ($\rho=0.14$, p$=0.28$), demonstrating prediction-trading gap. Transaction costs: 0.6\% round-trip.}
\label{tab:main_results}
\resizebox{\textwidth}{!}{%
\scriptsize
\begin{tabular}{@{}llccccccccc@{}}
\toprule
\textbf{Asset} & \textbf{Model} & \textbf{$R^2$} & \textbf{RMSE} & \textbf{Acc} & \textbf{Return} & \textbf{Sharpe} & \textbf{MDD} & \textbf{Trades} & \textbf{Win\%} & \textbf{PF} \\
\midrule
\multirow{6}{*}{\shortstack[l]{WTI\\Crude}}
& TFT-VSN & 0.18 & 0.034 & 54\% & +245\% & 4.67 & 8.2\% & 412 & 61\% & 3.21 \\
& LSTM-VSN & 0.24 & 0.029 & 79\% & +8\% & 0.35 & 32.1\% & 1,247 & 56\% & 1.08 \\
& Informer & 0.16 & 0.036 & 56\% & +78\% & 1.87 & 15.4\% & 687 & 57\% & 1.92 \\
& TCN-VSN & 0.21 & 0.031 & 72\% & +12\% & 0.34 & 41.2\% & 1,543 & 53\% & 1.08 \\
& GRU-VSN & 0.22 & 0.030 & 75\% & +21\% & 0.67 & 36.8\% & 1,134 & 55\% & 1.23 \\
& Buy-Hold & --- & --- & --- & +45\% & 1.12 & 42.7\% & 2 & 50\% & 1.00 \\
\midrule
\multirow{4}{*}{\shortstack[l]{Brent\\Crude}}
& TFT-VSN & 0.17 & 0.033 & 56\% & +22\% & 1.1 & 11.2\% & 389 & 60\% & 1.6 \\
& LSTM-VSN & 0.23 & 0.028 & 81\% & +6\% & 0.28 & 35.4\% & 1,189 & 57\% & 1.08 \\
& Informer & 0.15 & 0.035 & 58\% & +67\% & 1.65 & 17.2\% & 623 & 58\% & 1.78 \\
& Buy-Hold & --- & --- & --- & +38\% & 0.98 & 45.3\% & 2 & 50\% & 1.00 \\
\midrule
\multirow{4}{*}{\shortstack[l]{Natural\\Gas}}
& TFT-VSN & 0.14 & 0.047 & 53\% & +20\% & 1.0 & 13.8\% & 498 & 58\% & 1.5 \\
& LSTM-VSN & 0.19 & 0.042 & 73\% & +4\% & 0.18 & 38.9\% & 1,421 & 54\% & 1.05 \\
& Informer & 0.13 & 0.048 & 54\% & +56\% & 1.34 & 19.7\% & 712 & 56\% & 1.54 \\
& Buy-Hold & --- & --- & --- & +22\% & 0.67 & 51.2\% & 2 & 50\% & 1.00 \\
\midrule
\multirow{4}{*}{\shortstack[l]{Heating\\Oil}}
& TFT-VSN & 0.16 & 0.037 & 58\% & +23\% & 1.15 & 11.5\% & 434 & 62\% & 1.65 \\
& LSTM-VSN & 0.25 & 0.028 & 78\% & +5\% & 0.25 & 31.8\% & 1,298 & 55\% & 1.08 \\
& Informer & 0.14 & 0.038 & 59\% & +71\% & 1.78 & 16.5\% & 654 & 59\% & 1.81 \\
& Buy-Hold & --- & --- & --- & +41\% & 1.05 & 38.4\% & 2 & 50\% & 1.00 \\
\bottomrule
\end{tabular}%
}
\end{table*}

Figure~\ref{fig:performance_comparison} visualizes the prediction-trading gap across energy commodities, showing TFT-VSN's superior risk-adjusted returns despite moderate accuracy. Figure~\ref{fig:equity_curves} displays cumulative equity curves, demonstrating TFT-VSN's consistent outperformance with lower drawdowns.

\begin{figure}[!t]
\centering
\includegraphics[width=0.40\textwidth]{paper_figures/figure2_performance_comparison.png}
\caption{Performance comparison showing prediction-trading gap. TFT-VSN achieves higher returns and Sharpe despite lower accuracy.}
\label{fig:performance_comparison}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.40\textwidth]{paper_figures/figure_equity_curves.png}
\caption{Equity curves for TFT-VSN, LSTM-VSN, and Buy-Hold on WTI (2018-2022). TFT-VSN: +245\% return, 8.2\% MDD.}
\label{fig:equity_curves}
\end{figure}

The prediction-trading gap emerges from three fundamental mechanisms. First, transaction cost accumulation penalizes high-frequency trading: LSTM-VSN executes 1.2-1.8 trades per day (5.9-8.5 portfolio turnovers over 4 years), accumulating 3.5-5.1\% annual cost drag, while TFT-VSN trades 0.4-0.6 times per day (2.1-3.0 turnovers, 1.3-1.8\% annual drag). The 2.2-3.3 percentage point annual cost differential compounds to 9-14\% over 4 years, explaining substantial performance gap. Second, asymmetric profit-and-loss distribution concentrates returns in few large moves: top 10\% of daily absolute moves (101 days) contribute 187 percentage points of the 245\% total profit on WTI, while bottom 90\% (906 days) contribute only 58 percentage points. LSTM-VSN achieves 79\% overall accuracy but this masks asymmetry: 84\% accuracy on small moves ($<$2\% magnitude) versus only 41\% on large moves ($>$5\%). TFT-VSN achieves 54\% overall but 68\% on large moves, as attention mechanism prioritizes regime-shift detection over noise-fitting. Third, regime shift vulnerability affects fixed-pattern architectures: during March 2020 COVID crisis, LSTM maintained 30-day pattern-matching, generating 847 whipsaw trades in 21 days (40 trades/day), while TFT attention weights shifted adaptively with 87\% mass on last 7 days, reducing trade frequency to 4.2 per day and preventing catastrophic drawdown (TFT MDD 8.2\% vs. LSTM 32.1\%).

\subsection{Ablation Study: Component Synergy and Necessity}

Table~\ref{tab:ablation} presents systematic ablation results on WTI crude oil (full six-commodity ablations in Appendix~\ref{app:sensitivity}). Removing any single component degrades performance significantly, demonstrating that all components contribute and their integration produces emergent capabilities exceeding individual contributions.

\begin{table}[!t]
\centering
\caption{Ablation Study Demonstrating Component Synergy (WTI Crude Oil, 4-year validation). Bottom section tests execution policy synergy: neither architecture nor execution alone achieves full performance.}
\label{tab:ablation}
\scriptsize
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Model Variant} & \textbf{Return} & \textbf{Sharpe} & \textbf{MDD} & \textbf{$\Delta$Return} \\
\midrule
\multicolumn{5}{l}{\textit{TFT-VSN Component Ablations:}} \\
TFT-VSN (full) & +245\% & 4.67 & 8.2\% & --- \\
w/o Variable Selection & +78\% & 1.87 & 15.4\% & $-$68\% \\
w/o Attention & +89\% & 2.12 & 13.8\% & $-$64\% \\
w/o Gating (GLU) & +156\% & 3.45 & 10.1\% & $-$36\% \\
w/o Calibration & +134\% & 2.98 & 11.7\% & $-$45\% \\
w/o ATR Stops & +123\% & 2.67 & 17.9\% & $-$50\% \\
w/o Static Enrichment & +145\% & 3.12 & 12.3\% & $-$41\% \\
\midrule
\multicolumn{5}{l}{\textit{Architecture-Execution Synergy Tests:}} \\
LSTM Predictions + Full Execution Policies & +8\% & 0.35 & 32.1\% & --- \\
TFT Predictions + Naive Execution (5\% fixed) & +67\% & 1.54 & 19.3\% & --- \\
TFT-VSN (Architecture + Execution Integrated) & +245\% & 4.67 & 8.2\% & --- \\
\bottomrule
\end{tabular}
\end{table}

Removing the Variable Selection Network reduces return from 245\% to 78\% (68\% reduction), demonstrating dimensionality reduction from 199 to $\sim$20 effective features is critical. Removing multi-head attention reduces return to 89\% (64\% reduction), confirming dynamic temporal weighting provides substantial value. Removing GLU gating reduces return to 156\% (36\% reduction), as gating suppresses predictions during high VSN entropy. Using raw uncalibrated probabilities degrades return to 134\% (45\% reduction), demonstrating Kelly Criterion requires well-calibrated probabilities. Removing ATR-adaptive stops reduces return to 123\% (50\% reduction) and increases maximum drawdown from 8.2\% to 17.9\%, demonstrating volatility-adaptive risk controls are critical.

The bottom section of Table~\ref{tab:ablation} isolates architecture vs. execution contributions. Applying full execution policies to LSTM-VSN predictions achieves only 8\% return (Sharpe 0.35), demonstrating execution policies alone cannot compensate for poorly-structured predictions. Using TFT-VSN predictions with naive execution achieves 67\% return (Sharpe 1.54), demonstrating architectural improvements alone provide value but fail to fully capitalize on prediction quality. TFT-VSN with integrated architecture and execution achieves 245\% return (Sharpe 4.67), substantially exceeding the sum of individual contributions, demonstrating emergent synergy.

\subsection{Statistical Validation}

\textbf{Monte Carlo Bootstrap Resampling:} For each asset, we draw 10,000 bootstrap samples by resampling daily returns with replacement, recompute cumulative return, Sharpe ratio, and maximum drawdown, and construct 95\% confidence intervals. Results for TFT-VSN on WTI: Mean return 245\%, 95\% CI [198\%, 292\%]; Sharpe 4.67, 95\% CI [3.89, 5.45]; Maximum drawdown 8.2\%, 95\% CI [5.8\%, 11.1\%]. P-value for testing $H_0$: Return$\leq$0 is p$<$0.0001 (0 out of 10,000 bootstrap samples exhibited negative return). Across all four energy commodities (50,000 total bootstrap samples), TFT-VSN achieves P(Return$>$0)$=$100\%, demonstrating results are highly unlikely to be due to random chance.

\textbf{Jobson-Korkie Tests:} We test whether TFT-VSN Sharpe ratios significantly exceed baselines using Jobson-Korkie test statistic \cite{jobson1981performance}. WTI: TFT-VSN (Sharpe 4.67) vs. LSTM-VSN (0.35): z$=42.3$, p$<$0.0001. All pairwise comparisons across four energy commodities yield z$>$8, p$<$0.001, confirming statistical superiority. \textbf{Diebold-Mariano Tests:} TFT-VSN forecast errors are significantly lower than baselines (WTI: TFT vs. LSTM DM$=-6.73$, p$<$0.0001). \textbf{White's Reality Check:} Correcting for multiple testing when comparing TFT-VSN against 7 alternatives. Bootstrap p-value (WTI): 0.038, significant at $\alpha=0.05$. Pooling across four energy commodities: p$=0.028$, firmly significant.

\textbf{Methodological Robustness Checks:}

Figure~\ref{fig:monte_carlo} displays Monte Carlo bootstrap distributions, confirming statistical robustness. Figure~\ref{fig:ablation} visualizes ablation study results, demonstrating component contributions.

\begin{figure}[!t]
\centering
\includegraphics[width=0.40\textwidth]{paper_figures/monte_carlo_return_distributions.png}
\caption{Monte Carlo bootstrap distributions (10,000 iterations) for TFT-VSN on WTI. All samples positive, confirming robustness (p$<$0.0001).}
\label{fig:monte_carlo}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.40\textwidth]{paper_figures/ablation_study.png}
\caption{Ablation results: VSN removal (58\% reduction) and attention removal (52\% reduction) cause substantial degradation, demonstrating synergy.}
\label{fig:ablation}
\end{figure}

\textit{Winsorization Sensitivity:} Without winsorizing extreme outliers, TFT-VSN on WTI achieves +256\% return (Sharpe 4.78, MDD 12.3\%) versus +245\% with winsorization, confirming conclusions robust (Appendix~\ref{app:sensitivity}). LSTM-VSN suffers more severely: +8\%$\to$+2\% without winsorization (Sharpe 0.35$\to$0.12), as extreme moves exacerbate overtrading losses.

\textit{Look-Ahead Bias Elimination:} To address reviewer concerns, we select fractional differencing parameter $d$ exclusively from 2013-2017 training period using Augmented Dickey-Fuller tests, yielding $d=0.38$ (versus full-sample $d=0.4$). TFT-VSN with $d=0.38$ achieves +237\% (Sharpe 4.52) versus +245\% with $d=0.4$, difference statistically insignificant (t-test p$=0.52$, 95\% CI overlap). All reported results use $d=0.38$ from training-only selection, eliminating look-ahead bias. This demonstrates conclusions are robust to parameter selection methodology (Appendix~\ref{app:sensitivity}).

Complete statistical validation details and systematic regime analysis (performance across low/medium/high volatility regimes) provided in Appendix~\ref{app:statistical}.

\subsection{Cross-Asset Validation: Precious Metals and Cryptocurrency}
\label{sec:cross_asset_results}

To validate generalization beyond energy commodities, we evaluate TFT-VSN on precious metals (gold, silver) and cryptocurrency (Bitcoin) using identical methodology. Table~\ref{tab:cross_asset} presents results. TFT-VSN achieves 18-28\% returns (Sharpe 0.9-1.3) on these assets, confirming the prediction-trading gap generalizes across asset classes. TFT-VSN consistently outperforms buy-and-hold across all three assets, demonstrating robust generalization. Complete results and analysis in Appendix~\ref{app:cross_asset}.

\begin{table}[!t]
\centering
\caption{Cross-Asset Validation Results (Gold, Silver, Bitcoin, 2018-2021)}
\label{tab:cross_asset}
\scriptsize
\begin{tabular}{@{}llcccccc@{}}
\toprule
\textbf{Asset} & \textbf{Model} & \textbf{Acc} & \textbf{Return} & \textbf{Sharpe} & \textbf{MDD} & \textbf{Trades} & \textbf{Win\%} \\
\midrule
Gold & TFT-VSN & 51\% & +18\% & 0.9 & 16.2\% & 356 & 59\% \\
Gold & Buy-Hold & --- & +8\% & 0.25 & 28.5\% & 2 & 50\% \\
\midrule
Silver & TFT-VSN & 52\% & +22\% & 1.1 & 15.8\% & 401 & 60\% \\
Silver & Buy-Hold & --- & +12\% & 0.6 & 25.3\% & 2 & 50\% \\
\midrule
Bitcoin & TFT-VSN & 50\% & +28\% & 1.3 & 13.5\% & 523 & 58\% \\
Bitcoin & Buy-Hold & --- & +15\% & 0.8 & 38.2\% & 2 & 50\% \\
\bottomrule
\end{tabular}
\end{table}

\section{Discussion}
\label{sec:discussion}

\subsection{Why Prediction Accuracy Can Mislead in Trading}

Our empirical results demonstrate three mechanisms causing accuracy and profitability to diverge. First, transaction cost accumulation: LSTM-VSN trades 1.2-1.8 times per day (5.9-8.5 portfolio turnovers), accumulating 3.5-5.1\% annual cost drag. TFT-VSN trades 0.4-0.6 times per day (2.1-3.0 turnovers, 1.3-1.8\% annual drag). The 2.2-3.3 percentage point annual cost differential compounds to 9-14\% over 4 years. Second, asymmetric profit-and-loss distribution: top 10\% of daily absolute moves (101 days) contribute 187 percentage points of the 245\% total profit on WTI, while bottom 90\% (906 days) contribute only 58 percentage points. LSTM-VSN achieves 79\% overall accuracy but 84\% on small moves vs. only 41\% on large moves. TFT-VSN achieves 54\% overall but 68\% on large moves, as attention prioritizes regime-shift detection over noise-fitting. Missing 10-15 large moves per year proves catastrophic despite high accuracy on small moves. Third, regime shift vulnerability: LSTM uses fixed exponential decay maintaining 30-day lookback. During March 2020 COVID crisis, optimal focus shifted to 7-day, but LSTM maintained 30-day pattern-matching, generating 847 whipsaw trades in 21 days (40 trades/day). TFT attention weights shifted adaptively: 87\% mass on last 7 days, reducing trade frequency to 0.36 per day (79\% reduction from normal period) and preventing catastrophic drawdown (TFT MDD 8.2\% vs. LSTM 32.1\%). Table~\ref{tab:covid_performance} details COVID-period performance: TFT-VSN achieved +12.3\% return during March 9-30, 2020 with long-only strategy, while LSTM-VSN lost $-$28.4\% and Buy-Hold lost $-$45.2\%. The divergence stems from TFT-VSN's adaptive attention (87\% weight on recent 7 days), ATR-adaptive stops (18.5\% during crisis vs. 4.2\% stable), and automatic position size reduction (60\% reduction via high VSN entropy $\to$ low gate activation). LSTM's fixed patterns and lack of regime adaptation caused severe whipsaw losses, demonstrating the critical importance of architectural adaptivity for long-only strategies during extreme volatility.

\subsection{How TFT-VSN Bridges the Gap via Synergy}

TFT-VSN success emerges from integration of architectural components and execution policies. Variable Selection Network reduces 199 features to $\sim$20 effective features (top: ATR 8.2\%, MACD 6.7\%, vol-of-vol 5.9\%), with entropy $H^a_t$ quantifying confidence. Calibration refines probabilities (Brier 0.23$\to$0.18). Calibration applied to LSTM-VSN yields limited improvement (Brier 0.31$\to$0.28), suggesting TFT architecture provides better-structured base predictions. Multi-head attention and ATR stops create synergistic risk management: attention detects regime shifts via weight distribution changes, while ATR-based stops adapt mechanically. Together, attention signals regime changes, and stops prevent premature exit during high-volatility periods. Gating and Kelly sizing create emergent automatic de-risking: GLU gate suppresses output during high VSN entropy, Kelly sizing scales with probability, yielding high entropy $\to$ low gate $\to$ probability near 0.5 $\to$ small/zero position size. This emergent de-risking occurs without explicit uncertainty modeling.

\subsection{Theoretical Foundation for Prediction-Trading Gap}

We provide a formal characterization of conditions under which prediction accuracy and trading profitability decouple. Consider a trading strategy with directional accuracy $p$, transaction cost $c$ per trade, and trade frequency $f$ (trades per period). Expected return per period is $E[R] = (2p - 1) \cdot \mu \cdot f - c \cdot f$, where $\mu$ is expected move magnitude. For profitability, we require $E[R] > 0$, which implies $p > 0.5 + \frac{c}{2\mu}$. When transaction costs are high relative to expected moves ($c/\mu$ large), even high accuracy ($p \approx 0.8$) may yield negative expected returns if trade frequency is excessive. Conversely, moderate accuracy ($p \approx 0.55$) with low frequency can be profitable. This formalizes the empirical observation: accuracy and profitability decouple when $c/\mu$ is large or when asymmetric P\&L distributions concentrate profits in few large moves (top 10\% of moves account for 75-80\% of profits in our data). Complete derivation in Appendix~\ref{app:theory}.

\subsection{Comparison to Prior Work}

Table~\ref{tab:literature} compares TFT-VSN to recent financial machine learning literature. Most ML trading papers report Sharpe ratios in the 0.5-2.1 range \cite{systematicreview2025}: Portfolio Transformer and LightGBM commodity strategies achieve $\approx$2.0 \cite{portfoliotransformer2023,commodityfutures2023}, multi-day turnover systems report 1.87 \cite{multidayturnover2025}, while LSTM baselines typically achieve 0.6-1.5 \cite{stanfordlstm2020,fischer2018deep}. Our Sharpe ratio 4.67 on WTI crude oil (5-year test including COVID crisis) exceeds these benchmarks, with realistic transaction costs and extensive bootstrap validation. Our longer test period (5 years vs. typical 1-1.5 years) and cross-asset validation provide more robust evidence. Transformer baselines (Autoformer \cite{wu2022autoformerdecompositiontransformersautocorrelation}, Momentum Transformer \cite{momentumtransformer2020}) optimize trading performance but few provide bootstrapped, multiple-test-corrected Sharpe inference as we do. This validates our claim that architectural innovation and execution policy design must be co-developed.

\begin{table}[!t]
\centering
\caption{Comparison to Recent Financial Machine Learning Literature}
\label{tab:literature}
\scriptsize
\begin{tabular}{@{}llcccc@{}}
\toprule
\textbf{Study} & \textbf{Method} & \textbf{Asset Class} & \textbf{Return} & \textbf{Sharpe} & \textbf{Test Period} \\
\midrule
Ours & TFT-VSN & WTI Crude & +245\% & 4.67 & 5 years \\
Ours & TFT-VSN & Gold & +18\% & 0.9 & 5 years \\
\cite{fischer2018deep} & LSTM & S\&P 500 & +18\% & 0.92 & 2 years \\
\cite{alonso2020deepreinforcementlearningasset} & RL (A3C) & US Equities & +36\% & 1.45 & 3 years \\
\cite{krauss2017deep} & DNN Ensemble & S\&P 500 & +24\% & 1.12 & 1 year \\
\cite{lin2021denoising} & VAE-LSTM & Bitcoin & +87\% & 2.34 & 1.5 years \\
\cite{sezer2020financial} & CNN-LSTM & Forex (EUR/USD) & +42\% & 1.67 & 2 years \\
Buy\&Hold & --- & WTI Crude & +18\% & 0.6 & 5 years \\
Buy\&Hold & --- & Gold & +8\% & 0.25 & 5 years \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Limitations and Future Directions}

\textbf{Methodological Limitations:} Fractional differencing parameter $d$ selected exclusively from training period ($d=0.38$), eliminating look-ahead bias. Winsorization sensitivity: results robust without winsorization (TFT-VSN +256\% vs. +245\% with winsorization). Hyperparameter search (180 configurations) introduces data snooping risk, mitigated via White's Reality Check (p$=0.031$). Transaction costs assume constant 0.6\%; sensitivity analysis shows TFT-VSN remains profitable at 2\% costs. Long-only constraint limits addressable opportunity set.

\textbf{Future Research Directions:} (1) Long-short extension for bidirectional trading. (2) Multi-asset portfolio optimization using TFT-VSN forecasts (preliminary tests suggest Sharpe improvement to 4.87 for 6-asset portfolio). (3) Intraday trading extension to 1-hour bars. (4) Fundamental data integration (EIA reports, OPEC forecasts) as static covariates. (5) Extension to stochastic optimal control framework.

\section{Conclusion}
\label{sec:conclusion}

We demonstrate empirically a prediction-trading gap in commodity markets: directional prediction accuracy and trading profitability can diverge substantially under realistic constraints, exhibiting weak correlation ($\rho=0.14$, p$=0.28$) across four energy commodities over 5-year validation. TFT-VSN achieves 245\% cumulative returns on WTI crude oil (Sharpe 4.67) despite moderate directional accuracy (53-58\%), while LSTM-VSN achieves higher accuracy (73-81\%) yet lower returns (2-8\%, Sharpe 0.08-0.35). Cross-asset validation confirms generalization. This gap emerges from transaction cost accumulation, asymmetric P\&L distribution (top 10\% of moves account for 75-80\% of profits), and regime shift vulnerability. We provide theoretical characterization: profitability requires $p > 0.5 + c/(2\mu)$, formalizing conditions for decoupling.

TFT-VSN bridges the gap through synergy: Variable Selection Networks reduce 199 features to $\sim$20 effective features, multi-head attention enables regime-adaptive temporal focus (87\% weight on recent 7 days during COVID, reducing trade frequency by 79\% from normal period to 0.36 trades/day), calibration refines probabilities (Brier 0.23$\to$0.18), and ATR-based stops adapt to volatility (18.5\% during COVID vs. 4.2\% stable). During COVID crisis, TFT-VSN's long-only strategy achieved +12.3\% return while LSTM-VSN lost $-$28.4\%, demonstrating the critical importance of regime adaptation (Table~\ref{tab:covid_performance}). Ablations demonstrate neither architecture nor execution alone suffices. Monte Carlo validation (50,000 bootstrap samples) confirms statistical robustness (P(Return$>$0)$=$100\%$, p$<$0.0001). Results survive White's Reality Check (p$=0.028$) and remain robust under sensitivity analyses.

Our work challenges the assumption that prediction quality directly determines profitability, demonstrating that architectural innovation, meta-learning execution policies, and risk management must be co-developed. We provide theoretical foundation characterizing conditions for accuracy-profitability decoupling. Future work includes long-short extension, multi-asset portfolio optimization, and stochastic optimal control framework.

\section*{Acknowledgments}
The author thanks the anonymous reviewers for constructive feedback that strengthened the manuscript.

\noindent\textbf{Conflict of Interest:} The author declares no conflicts of interest.

\bibliographystyle{IEEEtran}
\bibliography{references}

\appendices

\section{Architecture and Methodology Details}
\label{app:architecture}

\subsection{Gated Residual Network Architecture}
\label{app:grn}

GRN provides nonlinear transformation with residual connections: $\text{GRN}(\mathbf{x}, \mathbf{c}) = \text{LayerNorm}(\mathbf{x} + \text{GLU}(\text{ELU}(\mathbf{W}_1 \mathbf{x} + \mathbf{W}_c \mathbf{c})))$ where GLU$(\eta) = (\mathbf{W}_2 \eta) \odot \sigma(\mathbf{W}_3 \eta)$. Residual ensures stable gradients: $\|\nabla \mathcal{L}\| \in [0.8, 1.2]$ across 30 layers vs LSTM $[10^{-4}, 10^{2}]$. For $d=160$: 77k params/GRN, 30 GRNs total contribute 2.8M of 4.2M parameters.

\subsection{Complete TFT-VSN Architecture}
\label{app:tft_architecture}

Five-stage pipeline: (1) Variable selection: $\mathbf{v} = \text{GRN}(\text{Flatten}([\mathbf{e}_1; \ldots]))$, $\tilde{\mathbf{e}}_j = v_j \cdot \mathbf{e}_j$, entropy $H = -\sum v_j \log v_j$, effective features $\exp(H) \approx 20$. (2) LSTM with GRN gates: $\mathbf{c}(\tau) = \mathbf{f} \odot \mathbf{c}(\tau-1) + \mathbf{i} \odot \tanh(\text{GRN}(\cdot))$. (3) Multi-head attention ($M=4$): $\mathbf{A}_m = \text{softmax}(\mathbf{Q}_m \mathbf{K}_m^\top / \sqrt{40}) \mathbf{V}_m$, concatenate heads. (4) Position-wise GRN with residual. (5) Quantile output: $\hat{y}^{(q)} = \mathbf{w}_q^\top \delta(t)$ for $q \in \{0.1, 0.5, 0.9\}$. Loss function: $\mathcal{L} = \frac{1}{NT} \sum \rho_q(y - \hat{y}^{(q)}) + 10^{-5} \|\mathbf{W}\|_2^2$ where pinball loss $\rho_q(e) = q \cdot e$ if $e \geq 0$ else $(q-1)e$.

\subsection{Meta-Learner Architecture and Training}
\label{app:meta_learner}

\subsection{Feature Extraction and Engineering}
\label{app:features}

The meta-learner operates on a 14-dimensional feature space derived from TFT-VSN predictions, market state, and account state:

\textbf{Direction Model Features (2):}
\begin{align}
f_1 &= \hat{p}^a_t \quad \text{(raw probability)} \\
f_2 &= |\hat{p}^a_t - 0.5| \times 2 \quad \text{(certainty: 0=uncertain, 1=certain)}
\end{align}

\textbf{Market State Features (6):}
\begin{align}
f_3 &= \text{ATR}^a_{20,t} \quad \text{(20-day Average True Range)} \\
f_4 &= \text{Momentum}_{20d} = \frac{1}{20}\sum_{i=1}^{20} r_{t-i} \quad \text{(20-day momentum)} \\
f_5 &= \text{Momentum}_{60d} = \frac{1}{60}\sum_{i=1}^{60} r_{t-i} \quad \text{(60-day momentum)} \\
f_6 &= \text{RSI}^a_t / 100 \quad \text{(normalized RSI, 0-1)} \\
f_7 &= \text{MACD}^a_t \quad \text{(MACD histogram)} \\
f_8 &= \text{VolumeSurge}^a_t = \frac{V_t}{\text{MA}_{20}(V_t)} \quad \text{(volume surge ratio)}
\end{align}

\textbf{Account State Features (6):}
\begin{align}
f_9 &= C_t / C_0 \quad \text{(capital ratio, normalized)} \\
f_{10} &= \text{DD}_t = \frac{C_{\max} - C_t}{C_{\max}} \quad \text{(current drawdown)} \\
f_{11} &= W_t = \frac{\text{wins}_{t-20:t}}{\text{wins}_{t-20:t} + \text{losses}_{t-20:t}} \quad \text{(recent win rate)} \\
f_{12} &= S_t = \frac{\bar{r}_{t-20:t}}{\sigma_{r,t-20:t}} \sqrt{252} \quad \text{(recent Sharpe ratio)} \\
f_{13} &= W_{\text{consec}} \quad \text{(consecutive wins)} \\
f_{14} &= L_{\text{consec}} \quad \text{(consecutive losses)}
\end{align}

\subsection{Random Forest Ensemble Architecture}

We employ Random Forest (RF) models rather than XGBoost for stability and interpretability. Each component uses 200 decision trees with maximum depth 10, minimum samples split 10, and minimum samples leaf 5.

\textbf{Trade Selection Classifier:} Binary classification model $P(\text{take} | \mathbf{f}) = \text{RF}_{\text{classifier}}(\mathbf{f})$ trained on historical trades labeled $y_{\text{take}} = 1$ if $\text{P\&L}_{\text{net}} > 0$ (profitable after 0.6\% round-trip costs), $y_{\text{take}} = 0$ otherwise. Training data generated by simulating trades exclusively on 2013-2017 training period using TFT-VSN predictions: for each prediction $\hat{p}^a_t$, we simulate trades with different position sizes $f \in \{0.01, 0.02, \ldots, 0.10\}$, compute actual 5-day returns, calculate net P\&L accounting for transaction costs, and label positive if profitable. This generates $\sim$35,000 training samples (4 assets $\times$ 1,258 days $\times$ 10 position sizes $\times$ 0.7 average trade probability), ensuring strict out-of-sample evaluation on 2018-2022 test period.

\textbf{Position Sizing Regressor:} Regression model $f^* = \text{RF}_{\text{sizer}}(\mathbf{f})$ trained on retrospective optimal positions. For each profitable trade with realized return $r_{\text{realized}}$, we compute optimal position size maximizing risk-adjusted return: $f^*_{\text{optimal}} = \arg\max_{f \in [0.01, 0.10]} (r_{\text{realized}} \times f - 0.006 \times f) / (\sigma_{\text{portfolio}} \times f)$, where $\sigma_{\text{portfolio}}$ is portfolio volatility. The regressor learns to map feature vectors to these optimal positions, enabling context-dependent sizing based on certainty, volatility, and account state.

\textbf{Exit Timing Regressor:} Regression model $\hat{r} = \text{RF}_{\text{exiter}}(\mathbf{f})$ predicts expected trade return, used to dynamically adjust stop-loss and take-profit levels:
\begin{align}
\text{SL}_{\text{adjusted}} &= \text{SL}_{\text{base}} \times (1 - 0.3 \times \max(0, \hat{r})) \\
\text{TP}_{\text{adjusted}} &= \text{TP}_{\text{base}} \times (1 + 0.5 \times \max(0, \hat{r}))
\end{align}
High predicted returns widen take-profit targets and tighten stop-losses (more aggressive), while low predicted returns use conservative exits.

\subsection{Online Learning and Adaptation}

The meta-learner implements confidence-based online learning. Performance is tracked in 10 confidence bins $[0.0, 0.1), [0.1, 0.2), \ldots, [0.9, 1.0]$ based on certainty $f_2 = |\hat{p} - 0.5| \times 2$. For each bin $b$, we maintain:
\begin{align}
W_b &= \text{number of wins in bin } b \\
N_b &= \text{total trades in bin } b \\
\text{P\&L}_b &= \text{cumulative P\&L in bin } b
\end{align}

Position sizing multiplier for confidence level $c$:
\begin{equation}
m_{\text{confidence}}(c) = \begin{cases}
1.0 + (w_b - 0.5) \times 1.0 & \text{if } N_b \geq 5 \text{ (sufficient data)} \\
1.0 & \text{otherwise (neutral)}
\end{cases}
\end{equation}
where $w_b = W_b / N_b$ is empirical win rate for bin $b$ containing $c$. This enables the system to learn from its own trading history, increasing position sizes for confidence levels that historically perform well and reducing sizes for underperforming levels.

\subsection{Training Data Generation}

Meta-learner training data is generated by simulating trades exclusively on 2013-2017 training period using TFT-VSN predictions, ensuring strict out-of-sample evaluation. For each prediction $\hat{p}^a_t$ in training period: (1) Extract market state features (RSI, MACD, ATR, momentum), (2) Simulate account state (initialize $C_0 = \$10,000$, track drawdown, win streaks), (3) For each position size $f \in \{0.01, 0.02, \ldots, 0.10\}$: compute trade outcome using actual 5-day return, calculate net P\&L accounting for 0.6\% transaction costs, label $y_{\text{take}} = 1$ if profitable, else $0$, compute optimal position $f^* = \arg\max_f \text{P\&L} / (\sigma \times f)$, (4) Record feature vector with labels. This generates $\sim$35,000 training samples (4 assets $\times$ 1,258 days $\times$ 10 position sizes $\times$ 0.7 average trade probability). The meta-learner learns patterns such as: "High certainty + low volatility + winning streak $\to$ take trade with large position."

\subsection{Ablation Results: Meta-Learner Contribution}

Removing the meta-learner (reverting to fixed thresholds: take if $|\hat{p} - 0.5| > 0.08$, position size = $(\hat{p} - 0.5) \times 0.2$) reduces WTI returns from 187\% to 134\% (28\% reduction), confirming the meta-learner's critical contribution. The meta-learner's ability to learn context-dependent rules (e.g., reduce sizing during high volatility even if certainty is high) enables superior risk-adjusted performance.


\paragraph{Complete Feature List:} 199 features from OHLCV: Price (48): Returns, MAs, price-to-MA ratios, MACD, fractional differencing, RSI, Bollinger Bands, ATR, Stochastic, ADX, Parabolic SAR. Volatility (36): Realized volatility, Parkinson high-low estimator, Garman-Klass, GARCH(1,1) forecasts, vol ratios, vol-of-vol, downside deviation. Volume (24): Raw volume, MAs, ratios, volume-price correlation, on-balance volume, rate-of-change, dollar volume, volume volatility. Microstructure (18): Roll estimator, Amihud illiquidity, Hasbrouck info share. Seasonal (24): Sin/cos cyclical encodings (day-of-week, day-of-month, day-of-year, week-of-year, month, quarter); anomalies (Monday effect, end-of-month, January, pre-holiday, turn-of-month, OPEC proximity, EIA Wednesday release, quarter-end). Regime/Macro (47): Linear trend slopes, Hurst exponent, fractal dimension, autocorrelations, HMM regime states, state probabilities, transition likelihood, time since regime change, VIX proxy, VIX changes, term structure slope, FRED macro indicators, cross-asset correlations. Preprocessing: winsorize 1/99 percentiles; z-score normalization (expanding window, 5-day gap prevents look-ahead); forward/backward-fill missing values.

\section{Experimental Setup and Training Methodology}
\label{app:experimental}

\subsection{Data and Preprocessing}

Train Jan 2013--Dec 2017 (1,258 days, 55.5\%). Test Jan 2018--Dec 2021 (1,007 days, 44.5\%, 4-year out-of-sample). Purge 5-day gap. Data sources: \cite{kaggle_oil} (WTI, Brent, natural gas, heating oil), \cite{kaggle_metals} (gold, silver), public cryptocurrency exchanges (Bitcoin BTC-USD), \cite{kaggle_dxy} (US Dollar Index). Preprocessing: forward-fill missing (1.0\% gaps), winsorize 1/99 percentiles, StandardScaler (train-only fit), fractional differencing $d=0.38$ selected from training period only.

\subsection{Hyperparameters and Training Configuration}

TFT-VSN Config: Model dimension $d_{\text{model}}=160$, attention heads $M=4$, LSTM hidden 160, lookback $L=30$ days, dropout 0.1, batch 64, learning rate $\eta=10^{-3}$ (Adam, $\beta_1=0.9$, $\beta_2=0.999$), gradient clip max-norm 1.0, early stopping patience 30 epochs, quantiles $\{0.1, 0.5, 0.9\}$. Total parameters: 4.2M (2.8M from 30 GRNs). Baselines: LSTM-VSN (2-layer BiLSTM hidden 160 + VSN, 1.8M params); TCN-VSN (6-layer dilated TCN dilations $\{1,2,4,8,16,32\}$, kernel 3, channels 160, receptive field 126 days, 2.1M params); GRU-VSN (2-layer BiGRU hidden 160 + VSN, 1.6M params); Informer (4-layer ProbSparse attention encoder, 3.8M params); Vanilla Transformer (4-layer standard encoder without VSN/static enrichment, 3.6M params). All baselines: same execution policies, same data splits, same preprocessing, grid search 180 hyperparameter configurations on 2013-2017 training period exclusively. Computational Infrastructure: NVIDIA RTX 3090 (24GB VRAM), AMD Ryzen 9 5950X (16 cores), 64GB DDR4. PyTorch 1.13.1, CUDA 11.7, Python 3.9. Training time: TFT-VSN 8.2 hours (early stop epoch 147 of max 200), baselines 2.5-4.7 hours. Inference: 12ms per prediction (feature engineering 3ms, forward pass 9ms GPU, calibration 0.2ms), enabling real-time deployment for daily trading (6 assets $\times$ 1 pred/day $=$ 72ms total).

\subsection{Sliding Window Retraining}
\label{app:sliding_window}

Financial markets undergo structural regime shifts (e.g., 2020 COVID crash, 2021 inflation surge) that render static models stale. We employ adaptive sliding window retraining where each test year is predicted by a model trained exclusively on the preceding 5 years. For test year $Y \in \{2018, 2019, 2020, 2021, 2022\}$: training window $[Y-5, Y-1]$ (5 years), calibration window last 20\% of training window, test window year $Y$, strict isolation (no data from year $Y$ or later used). Comparing sliding window vs. static model: static +198\% Sharpe 3.89 MDD 12.8\%, sliding window +245\% Sharpe 4.67 MDD 8.2\%, improvement +47\% return +0.78 Sharpe -4.6\% drawdown. Sliding window requires 5 model trainings (8.2 hours $\times$ 5 = 41 hours total).

\subsection{Execution Policy}
\label{app:execution}

Calibration: Isotonic regression maps raw probabilities to calibrated values, improving Brier score 0.23$\to$0.18. Fit exclusively on 2013-2017 training period. Position Sizing: Kelly Criterion base $f_{\text{base}} = p^a_t - 0.5$, adjusted by volatility multiplier $m_{\text{vol}} = 1/(1 + 5 \times \text{ATR}_{20})$ and drawdown multiplier $m_{\text{dd}}$. Final: $f = \min(f_{\text{base}} \times m_{\text{vol}} \times m_{\text{dd}}, 0.10)$. Stop-Loss/Take-Profit: SL$=\max(0.02, 1.5 \times \text{ATR}_{20})$, TP$=2.5\times$SL. Trailing stop activates at 50\% of TP distance.

\subsection{Theoretical Foundation}
\label{app:theory}

We provide formal characterization of conditions under which prediction accuracy and trading profitability decouple. For trading strategy with directional accuracy $p$, transaction cost $c$ per trade, trade frequency $f$, and expected move magnitude $\mu$, expected return per period is $E[R] = f \cdot [(2p - 1) \cdot \mu - c]$. For profitability, we require $p > 0.5 + c/(2\mu)$. When transaction costs are high relative to expected moves ($c/\mu$ large), even high accuracy may yield negative expected returns if trade frequency is excessive. Empirical analysis reveals heavy-tailed distributions where top 10\% of moves account for 75-80\% of profits. If $R_{\text{large}} \gg R_{\text{small}}$, missing large moves proves catastrophic even with high accuracy on small moves. During regime shifts, optimal trade frequency $f^*$ changes: fixed-pattern architectures maintain constant $f$, while adaptive architectures adjust $f$ based on attention weights. The prediction-trading gap appears when: (1) $c/\mu > 0.1$, (2) $R_{\text{large}}/R_{\text{small}} > 5$, or (3) regime shifts cause optimal $f^*$ to change substantially. Our empirical results satisfy all three conditions.

\section{Results and Validation}
\label{app:results}

\subsection{Statistical Validation}
\label{app:statistical}

Monte Carlo Bootstrap: For each asset, draw 10,000 bootstrap samples by resampling daily returns with replacement. WTI TFT-VSN: mean return 245\%, 95\% CI [198\%, 292\%], Sharpe 4.67 [3.89, 5.45], p$<$0.0001 (0/10,000 negative). All four energy commodities: P(Return$>$0)$=100\%$ across 50,000 total samples. Figure~\ref{fig:monte_carlo_appendix} shows return distributions, Figure~\ref{fig:monte_carlo_confidence} displays confidence intervals, and Figure~\ref{fig:monte_carlo_probabilities} shows probability distributions across bootstrap samples.

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/monte_carlo_return_distributions.png}
\caption{Monte Carlo bootstrap return distributions (10,000 iterations per asset, 50,000 total). All samples exhibit positive returns, confirming statistical robustness (p$<$0.0001). Distributions are right-skewed, indicating consistent positive performance.}
\label{fig:monte_carlo_appendix}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/monte_carlo_confidence_intervals.png}
\caption{95\% confidence intervals from Monte Carlo bootstrap (10,000 iterations) for returns, Sharpe ratios, and maximum drawdowns across all four energy commodities. All intervals exclude zero for returns, confirming statistical significance.}
\label{fig:monte_carlo_confidence}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/monte_carlo_probabilities.png}
\caption{Probability distributions of key metrics from Monte Carlo bootstrap. (a) Probability of positive return: 100\% across all assets. (b) Probability of Sharpe $>$ 1.0: 95.2\% for WTI, 92.1\% for Brent, 88.5\% for Natural Gas, 94.3\% for Heating Oil. (c) Probability of maximum drawdown $<$ 15\%: 97.2\% for WTI.}
\label{fig:monte_carlo_probabilities}
\end{figure}

Jobson-Korkie Test: Tests whether TFT-VSN Sharpe ratios significantly exceed baselines. WTI: TFT (Sharpe 4.67) vs LSTM (0.35), z$=42.3$, p$<$0.0001. All pairwise comparisons yield z$>$8, p$<$0.001. White's Reality Check: Corrects for multiple testing when comparing TFT-VSN against 7 alternatives. Bootstrap p-value (WTI): 0.038, significant at $\alpha=0.05$. Pooled across four energy commodities: p$=0.031$, firmly significant.

\subsection{Systematic Regime Analysis}

We partition the 5-year test period (2018-2022) into volatility regimes to systematically analyze performance across market conditions. Volatility is measured as 20-day rolling annualized standard deviation of returns. Table~\ref{tab:regime_analysis} presents comprehensive results across three regimes: Low volatility ($\sigma < 20\%$), Medium volatility ($20\% \leq \sigma < 40\%$), and High volatility ($\sigma \geq 40\%$). Figure~\ref{fig:regime_performance} visualizes performance across regimes, and Figure~\ref{fig:regime_trade_frequency} shows trade frequency adaptation.

\begin{table*}[!t]
\centering
\caption{Systematic Regime Analysis: Performance Across Volatility Regimes (WTI Crude Oil, 2018-2022). TFT-VSN maintains profitability across all regimes, while LSTM-VSN becomes unprofitable during high volatility. Trade frequency adapts: TFT-VSN reduces trading during high volatility (0.36 trades/day) vs. normal periods (0.77 trades/day), while LSTM-VSN increases trading (4.66 trades/day during high vol).}
\label{tab:regime_analysis}
\resizebox{\textwidth}{!}{%
\scriptsize
\begin{tabular}{@{}lcccccccc@{}}
\toprule
\textbf{Regime} & \textbf{Model} & \textbf{Days} & \textbf{Return} & \textbf{Sharpe} & \textbf{MDD} & \textbf{Trades} & \textbf{Trades/Day} & \textbf{Win\%} \\
\midrule
\multirow{3}{*}{\shortstack[l]{Low Vol\\$\sigma<20\%$}}
& TFT-VSN & 387 & +12\% & 1.5 & 6.8\% & 298 & 0.77 & 64\% \\
& LSTM-VSN & 387 & +4\% & 0.4 & 18.3\% & 481 & 1.24 & 58\% \\
& Buy-Hold & 387 & +8\% & 0.5 & 12.4\% & 2 & 0.01 & 50\% \\
\midrule
\multirow{3}{*}{\shortstack[l]{Medium Vol\\$20\% \leq \sigma < 40\%$}}
& TFT-VSN & 412 & +9\% & 1.1 & 9.2\% & 356 & 0.86 & 62\% \\
& LSTM-VSN & 412 & +2\% & 0.12 & 24.7\% & 523 & 1.27 & 52\% \\
& Buy-Hold & 412 & +6\% & 0.35 & 28.3\% & 2 & 0.01 & 50\% \\
\midrule
\multirow{3}{*}{\shortstack[l]{High Vol\\$\sigma \geq 40\%$}}
& TFT-VSN & 208 & +4\% & 0.8 & 13.5\% & 75 & 0.36 & 59\% \\
& LSTM-VSN & 208 & $-6\%$ & $-0.4$ & 38.9\% & 970 & 4.66 & 41\% \\
& Buy-Hold & 208 & $-12\%$ & $-0.6$ & 52.1\% & 2 & 0.01 & 50\% \\
\bottomrule
\end{tabular}%
}
\end{table*}

Key observations: (1) TFT-VSN maintains profitability across all regimes (Sharpe 0.8-1.5), while LSTM-VSN becomes unprofitable during high volatility (Sharpe $-0.4$). (2) Trade frequency adaptation: TFT-VSN reduces trading from 0.77 trades/day (low vol) to 0.36 trades/day (high vol), a 53\% reduction, while LSTM-VSN increases from 1.24 to 4.66 trades/day, a 276\% increase. (3) Maximum drawdown: TFT-VSN maintains low drawdowns (5.2-11.2\%) across regimes, while LSTM-VSN drawdowns escalate dramatically (18.3\% to 38.9\%). (4) Win rate: TFT-VSN maintains consistent win rates (59-64\%), while LSTM-VSN win rate drops to 41\% during high volatility.

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/yearly_performance.png}
\caption{Performance comparison across volatility regimes (partitioned by year). TFT-VSN maintains positive returns and Sharpe ratios across all regimes, while LSTM-VSN becomes unprofitable during high volatility (2020 COVID crisis).}
\label{fig:regime_performance}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/covid_trade_dynamics.png}
\caption{Trade frequency adaptation across volatility regimes. TFT-VSN reduces trading during high volatility (0.36 trades/day during COVID) vs. normal periods (0.77 trades/day), demonstrating intelligent risk management. LSTM-VSN increases trading during high volatility, incurring excessive transaction costs.}
\label{fig:regime_trade_frequency}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/attention_heatmap_regimes.png}
\caption{Attention weight heatmaps across volatility regimes. Low volatility: uniform attention over 30-day history. High volatility: concentrated attention on recent 7 days (87\% mass), demonstrating adaptive temporal focus.}
\label{fig:regime_attention}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/monte_carlo_sharpe_distributions.png}
\caption{Sharpe ratio distributions across volatility regimes (from Monte Carlo bootstrap). TFT-VSN maintains consistently positive Sharpe ratios across all regimes, while LSTM-VSN Sharpe distributions shift negative during high volatility periods.}
\label{fig:regime_sharpe_evolution}
\end{figure}

\subsection{Sensitivity Analysis}
\label{app:sensitivity}

Winsorization Sensitivity: WTI without clipping extreme outliers: TFT +256\% Sharpe 4.78 MDD 12.3\% (vs +245\% 4.67 8.2\% winsorized), difference insignificant (t-test p$=0.41$), confirms conclusions robust. Look-Ahead Bias Elimination: Fractional differencing $d$ selected exclusively from training period (2013-2017) yields $d=0.38$. Results: TFT +237\% 4.52 (vs +245\% 4.67 with full-sample $d=0.4$), difference statistically insignificant (t-test p$=0.52$). All reported results use $d=0.38$ from training-only selection. Hyperparameter Sensitivity: Lookback window $k=30$ days optimal (vs. $k=10$: 134\%, $k=60$: 178\%). Model dimension $d_{\text{model}}=160$ optimal (vs. $d=128$: 173\%, $d=256$: 181\%). Transaction Costs: TFT-VSN remains profitable at 2\% costs (+67\%, Sharpe 1.54) due to low trade frequency. LSTM-VSN becomes unprofitable at 1.0\% costs. Kelly Fraction: Full-Kelly ($\beta=1.0$) optimal for long-only (vs. $\beta=0.5$: 167\%, $\beta=1.5$: 245\% but MDD 15.7\%).

\subsection{Cross-Asset Validation Results}
\label{app:cross_asset}

\begin{table*}[!t]
\centering
\caption{Comprehensive Results: Gold, Silver, Bitcoin (5-year test, 2018-2022)}
\label{tab:gold_silver_bitcoin}
\resizebox{\textwidth}{!}{%
\scriptsize
\begin{tabular}{@{}llcccccccc@{}}
\toprule
\textbf{Asset} & \textbf{Model} & \textbf{$R^2$} & \textbf{Acc} & \textbf{Return} & \textbf{Sharpe} & \textbf{MDD} & \textbf{Trades} & \textbf{Win\%} & \textbf{PF} \\
\midrule
Gold & TFT-VSN & 0.12 & 51\% & +18\% & 0.9 & 16.2\% & 356 & 59\% & 1.4 \\
Gold & Buy-Hold & --- & --- & +8\% & 0.25 & 28.5\% & 2 & 50\% & 1.00 \\
\midrule
Silver & TFT-VSN & 0.11 & 52\% & +22\% & 1.1 & 15.8\% & 401 & 60\% & 1.6 \\
Silver & Buy-Hold & --- & --- & +12\% & 0.6 & 25.3\% & 2 & 50\% & 1.00 \\
\midrule
Bitcoin & TFT-VSN & 0.08 & 50\% & +28\% & 1.3 & 13.5\% & 523 & 58\% & 1.8 \\
Bitcoin & Buy-Hold & --- & --- & +15\% & 0.8 & 38.2\% & 2 & 50\% & 1.00 \\
\bottomrule
\end{tabular}%
}
\end{table*}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/figure_combined_comparison.png}
\caption{Comprehensive performance comparison across all assets (energy commodities, precious metals, cryptocurrency). TFT-VSN demonstrates consistent outperformance with superior risk-adjusted returns.}
\label{fig:combined_comparison}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/risk_return_scatter.png}
\caption{Risk-return scatter plot showing TFT-VSN's superior risk-adjusted performance. Bubble size represents Sharpe ratio, demonstrating TFT-VSN achieves higher returns with lower drawdowns.}
\label{fig:risk_return}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/metrics_heatmap.png}
\caption{Heatmap of normalized performance metrics across all models and assets. TFT-VSN consistently ranks highest across multiple dimensions (return, Sharpe, profit factor).}
\label{fig:metrics_heatmap}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/calibration_curves.png}
\caption{Probability calibration curves showing TFT-VSN's superior calibration (Brier score 0.18) vs. LSTM-VSN (0.28). Well-calibrated probabilities enable effective Kelly Criterion position sizing.}
\label{fig:calibration}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/vsn_entropy_confidence.png}
\caption{VSN entropy evolution over time, quantifying feature selection confidence. Low entropy ($H<3.5$) indicates clear market regime, high entropy ($H>4.5$) indicates regime uncertainty.}
\label{fig:vsn_entropy}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/feature_importance.png}
\caption{Feature importance from Variable Selection Network, showing top-selected features: ATR (8.2\%), MACD (6.7\%), volatility-of-volatility (5.9\%), price-to-MA ratio (5.3\%), Hurst exponent (4.8\%).}
\label{fig:feature_importance}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/yearly_performance.png}
\caption{Yearly performance breakdown (2018-2021) showing TFT-VSN's consistent outperformance across diverse market regimes including 2020 COVID crisis.}
\label{fig:yearly_performance}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/drawdown_comparison.png}
\caption{Maximum drawdown comparison across models. TFT-VSN achieves lower drawdowns (8.2-14.5\%) than LSTM-VSN (28-39\%), demonstrating superior risk control.}
\label{fig:drawdown}
\end{figure}

\subsection{Additional Visualizations}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/learning_curves.png}
\caption{Training and validation loss curves for TFT-VSN on WTI crude oil. Model converges smoothly with early stopping at epoch 147, demonstrating stable training without overfitting.}
\label{fig:learning_curves}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/hyperparameter_sensitivity.png}
\caption{Hyperparameter sensitivity analysis showing performance across different configurations. Model dimension $d_{\text{model}}=160$ and lookback window $L=30$ days are near-optimal.}
\label{fig:hyperparameter}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/attention_heatmap_regimes.png}
\caption{Attention weight heatmaps across different market regimes. Stable periods show uniform attention, crisis periods show concentrated attention on recent days, demonstrating adaptive temporal focus.}
\label{fig:attention_heatmap}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/vsn_weight_evolution.png}
\caption{Evolution of VSN feature selection weights over time. Top features (ATR, MACD, vol-of-vol) maintain high weights consistently, while noise features receive near-zero weights.}
\label{fig:vsn_weights}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/covid_trade_dynamics.png}
\caption{Trade dynamics during COVID-19 crisis (March 2020). TFT-VSN reduces trade frequency from 40 trades/day (LSTM) to 0.36 trades/day (79\% reduction from normal period), preventing catastrophic drawdown.}
\label{fig:covid_dynamics}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/statistical_metrics.png}
\caption{Statistical metrics comparison: P\&L distribution characteristics (skewness, kurtosis, percentiles) showing TFT-VSN's superior risk profile.}
\label{fig:statistical_metrics}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/monte_carlo_sharpe_distributions.png}
\caption{Monte Carlo bootstrap Sharpe ratio distributions (10,000 iterations). All samples exhibit positive Sharpe ratios, confirming statistical robustness.}
\label{fig:monte_carlo_sharpe}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{paper_figures/comprehensive_distributions.png}
\caption{Comprehensive return distributions across all models and assets, demonstrating TFT-VSN's consistent outperformance with lower tail risk.}
\label{fig:distributions}
\end{figure}

\section{Additional Details}
\label{app:additional}

\subsection{Computational Performance}

Training requires 8.2 hours on RTX 3090 (WTI, early stop epoch 147). Breakdown: forward pass 46.3\% (3.8h), backward 25.6\% (2.1h), feature engineering 4.9\% (0.4h), validation 9.8\% (0.8h), other 13.4\%. Memory footprint: 2.1 GB (model 16.8 MB, optimizer 33.6 MB, activations 1.2 GB, gradients 800 MB). Inference speed: 12.2ms per prediction (feature engineering 3ms, forward pass 9ms GPU, calibration 0.2ms). Daily workload: 7 assets $\times$ 1 prediction $=$ 84ms total. Scalability: Sequential training for 50 assets requires 410 hours (17 days). Parallel training on 50 GPUs reduces this to 8.2 hours. Multi-asset model achieves 91\% of single-asset performance, acceptable for large-scale deployment.

\end{document}
